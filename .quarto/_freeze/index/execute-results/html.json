{
  "hash": "d6e8e52c73dd3eddd1a594449ec99278",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Untitled\"\nformat: html\neditor: visual\n---\n\n---\ntitle: \"<p style=\\\"color:black,text-align:center\\\">Design of Experiment</p>\"\nauthor: \n  - name: <font color=#ff6600><b>Biometrics Unit</b></font> \n    affiliation: <font color=#ff6600><b>International Institute of Tropical Agriculture (IITA)</b></font>\nformat:\n  html:\n    html-math-method: mathjax\n    css: \"style.css\"\n    toc: true\n    toc-location: right\n    toc_float:\n    collapsed: True\n    smooth_scroll: true\n    code_folding: show\n    number_sections: false\n    theme: readable\n    highlight: monochrome\n    fig_width: 5\n    fig_height: 5\n    fig_caption: true\n    df_print: paged\n    xaringan::moon_reader: null\n    lib_dir: libs\n    nature:\n      highlightStyle: github\n---\n\n\n\n# [**Summarizing Quantitative Data**]{style=\"color: #2C6D26;\"}\n\n## [Central Tendency]{style=\"color: #002D62;\"}\n\nCentral tendency is an important statistical measure of quantitative data. It identifies a single value as representative of an entire distribution of the collected data. The **Mean**, **Median**, and **Mode** are three of the common ways to measure central tendency. Other measurements, such as a trimmed Mean, weighted Mean, geometric Mean, and harmonic Mean, are not covered in this course.\n\n### **Mean**\n\nThe most used measure of central tendency is the Mean. The average of the data is the Mean. It is computed by adding all the values in the data set divided by the number of observations in it. Extreme values can easily alter the Mean, which is one of the Mean's shortcomings. i.e. sensitive to extreme values.\n\nTo calculate the Mean, you first add all the numbers together (3 + 11 + 4 + 6 + 8 + 9 + 6 = 47). Then you divide the total sum by the number of scores used (47 / 7 = 6.7). In this example, the Mean or average of the number set is 6.7.\n\nUse the Mean to describe the sample with a single value that represents the center of the data. Many statistical analyses use the Mean as a standard measure of the center of the distribution of the data. The Median and the Mean both measure central tendency.\n\n### **Median**\n\nThe Median is the value in the ordered data that is in the middle. The most critical step in calculating the Median is to arrange the data in ascending order from least to largest. Extreme values can not easily alter the Median. i.e. resistant to extreme values. When the dataset contains an even number of values, then the Median value of the dataset can be found by taking the Mean of the middle two values\n\n### **Mode**\n\nThe Mode is the most often occurring value in the data. It's crucial to keep in mind that the dataset could have multiple Modes. Extreme values can not easily alter the Mode. i.e. resistant to extreme values.\n\nLet's import the needed data with this command to calculate the Mean, and Median.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) \ndat <- read_excel(\"Data Summary.xlsx\", sheet=\"Mean\")   \nmean(dat$X)   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 82.1\n```\n\n\n:::\n\n```{.r .cell-code}\nmedian(dat$X) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 81\n```\n\n\n:::\n:::\n\n\n\nLet's see what happens to the Mean and Median if we mistakenly replace a number with an extreme value\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(dat$Y)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 153.1\n```\n\n\n:::\n:::\n\n\n\nThe extreme value distorts the Mean.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(dat$Y) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 84\n```\n\n\n:::\n:::\n\n\n\nThe Median is not really affected by the extreme value because of its characteristics of `resistant to extreme values`.\n\nMeasures of central tendency are chosen based on the characteristics of the data.\n\n-   All three central tendency measurements hold true for continuous data with a symmetrical distribution. However, because the Mean takes into account every value in the dataset or distribution, the analyst typically employs it.\n\n-   The Median is the most accurate way to determine the central tendency in a skewed distribution.\n\n-   The best options for determining the central tendency, if you have the original data, are the Median and the Mode.\n\n-   The Mode is the most effective way to determine the central tendency when dealing with categorical data.\n\n## [Measure of Spread (Variability/Dispersion)]{style=\"color: #002D62;\"}\n\nA summary statistic that indicates the amount of dispersion in a dataset is known as a measure of spread. Measures of spread describe how similar or varied the set of observed values is for a specific variable (data item). Summarising the dataset can help us understand the data, especially when the dataset is large.\n\n**Variance**, **standard deviation**, and **standard error** are three of the commonly used measures of spread.\n\nSpread is in the context of the distribution of dataset points. A low value of spread indicates that the data points tend to be clustered tightly around the center while a high value of spread indicates the data points are far away from the center. To demonstrate the idea of spread, let's consider these two different variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) \ndat1 <- read_excel(\"Data Summary.xlsx\", sheet=\"Spread\") \nmean(dat1$spread01)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n\n```{.r .cell-code}\nmedian(dat1$spread01) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) \ndat1 <- read_excel(\"Data Summary.xlsx\", sheet=\"Spread\")   \nmean(dat1$spread02)   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n\n```{.r .cell-code}\nmedian(dat1$spread02)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 30\n```\n\n\n:::\n:::\n\n\n\nThe two datasets have the same center, but how spread out are the values?. While a measure of central tendency describes the typical values, measures of spread define how far away the data points are from the center.\n\nLet’s examine the spread of the above variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(dat1$spread01)   \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 200\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(dat1$spread02) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 40\n```\n\n\n:::\n:::\n\n\n\nWe can see the variability in how spread out the data points are from each other.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsd(dat1$spread01) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14.14214\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(dat1$spread02) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.324555\n```\n\n\n:::\n:::\n\n\n\nThis also shows the difference in their standard deviations.\n\n# [**Summarizing Qualitative Data**]{style=\"color: #2C6D26;\"}\n\nOnce we have determined a variable to be qualitative (categorical), we need tools to summarize the data.\n\n-   The best way to summarize categorical data is to use frequencies (counts) and percentages (proportions).\n\n-   We can also summarize qualitative data by graphing the data using bar plots, histogram etc.\n\n## **Frequencies (counts)**\n\nThe quantity or the total number of an item in a collection or a group is simply referred to as frequency. The number of times an event or observation occurred during an experiment or research is known as its frequency in statistics. It can alternatively be understood as the simple count of an occurrence.\n\n## **Percentages (proportions)**\n\nA percentage is a fraction or part of the total that possesses a certain characteristic.\n\nLet’s consider an example:\n\nIn a survey of 20 participants, a question was asked about their choice of a political party. Their responses are in a vector called *pol_party*\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) \ndat2 <- read_excel(\"Data Summary.xlsx\", sheet=\"Poll\") \n```\n:::\n\n\n\nWe can easily summarize their responses within a few minutes, but it becomes difficult when the number of respondents is 100 and above.\n\nWe can use the function **table()** and **prop.table()** to obtain the frequency and proportion.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Frequency  \ntable(dat2$pol_party) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n APC NNPP  PDP  SDP \n   8    4    5    3 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Proportion  \nprop.table(table(dat2$pol_party)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n APC NNPP  PDP  SDP \n0.40 0.20 0.25 0.15 \n```\n\n\n:::\n:::\n\n\n\n# [**Data Summary: Practical**]{style=\"color: #2C6D26;\"}\n\n-   Import **Example-02.csv** into R and save in an object named **example02**\n\n-   filter the object using the year `1970` and save it to a new object named **example02.70**\n\n-   using the new object, summarize:\n\n-   the qualitative variables\n\n-   the first three quantitative variables\n\n# [**Correlation**]{style=\"color: #2C6D26;\"}\n\nCorrelation is a bivariate analysis that measures the strength of association between two variables. In statistics, the value of the correlation coefficient varies between -1 to +1. When the value of the correlation coefficient lies around ± 1, then it is said to be a perfect degree of association between the two variables. As the correlation coefficient value goes towards 0, the relationship between the two variables is weak.\n\nA common statistic to show the strength of a relationship that exists between two continuous variables is called the Pearson correlation coefficient or just correlation coefficient. We may want to calculate the correlation coefficient between height and weight for example.\n\nTwo common types of correlation tests will be discussed in this session:\n\n-   Pearson’s correlation\n\n-   Spearman’s correlation\n\nThe function **cor.test()** in base R can be used to test for association/correlation.\n\nThe arguments needed are:\n\n-   x, y: Numeric vectors of the same length\n-   method: Correlation method i.e. *(\"pearson\", \"spearman\")*\n\n## [Pearson’s Correlation]{style=\"color: #002D62;\"}\n\nPearson’s correlation is a parametric test widely used in statistics to measure the degree of the relationship between linear related variables and both variables should be normally distributed.\n\nFor illustration, let's consider the `australia.soybean` data, a multi-environment trial of 58 varieties of soybeans, in 4 locations across 2 years in Australia and examine the relationship/association between `yield` and `oil`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|message=FALSE\n#Pearson correlation \nlibrary(tidyverse) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3 <- read_csv(\"summary.australia.soybean.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 58 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gen\ndbl (6): yield, height, lodging, size, protein, oil\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ncor.test(dat3$yield, dat3$oil, method= \"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  dat3$yield and dat3$oil\nt = 8.82, df = 56, p-value = 3.528e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6278966 0.8528460\nsample estimates:\n      cor \n0.7625239 \n```\n\n\n:::\n:::\n\n\n\nThis examines the relationship between yield and oil of the Australian soybean. The test statistic, t(8.82) indicates how many standard deviations away from zero the sample is, with p-vale (3.528e-12) indicating that there is a statistically significant correlation between the yield and oil of the Australian soybean.The sample estimates correlation coefficient (0.7625) which is very close to 1, indicates a strong positive linear relationship between the yield and oil of the soybean.\n\n## [Spearman’s Correlation]{style=\"color: #002D62;\"}\n\nSpearman’s rank-order correlation coefficient is a rank-based version of Pearson’s correlation coefficient. It does not rely on any assumption about the distributions of the variables. It is a measure of rank correlation, i.e., the similarity of the orderings of the data when ranked by each of the quantities.\n\nLet's examine the association between `Height` and `DaystoFlower`, assuming the data are not normally distributed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Spearman correlation  \nlibrary(readxl) \ndat4 <- read_excel(\"correlations.xlsx\") \n\ncor.test(dat4$Height, dat4$DaystoFlower, method=\"spearman\")  \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in cor.test.default(dat4$Height, dat4$DaystoFlower, method =\n\"spearman\"): Cannot compute exact p-value with ties\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tSpearman's rank correlation rho\n\ndata:  dat4$Height and dat4$DaystoFlower\nS = 1169.8, p-value = 0.2938\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2404159 \n```\n\n\n:::\n:::\n\n\n\nThis examines the relationship between height and days to flowering of the plant. The test statistic S(1169.8), in the context of Spearman's correlation, this value relates to the sum of the ranks associated with the differences between the ranks of the two variables. The p-value is reported as 0.2938 implying that there is no statistical significance between height and days to flowering of the plant. The sample estimates of the Spearman correlation coefficient $p$ (0.2404). This suggests a weak positive correlation between the variables, indicating that as one increases, the other tends to also increase, but the relationship is not strong.\n\n## [Multiple Correlation]{style=\"color: #002D62;\"}\n\nSo far, we have seen how to correlate two quantitative variables together using the Pearson and Spearman rank method. It is also possible to correlate multiple quantitative variables together using either of the methods described above depending on the underlying assumption. We recommend the function **rcorr()** in the library **Hmisc** to examine the multiple association/correlation for all possible pairs of quantitative variables.\n\nThe arguments needed are:\n\n-   x, y: Numeric matrix with at least five rows and atleast two columns\n\n-   type: Specify the correlation method i.e. *(\"pearson\", \"spearman\")*\n\nThe `rcorr` function returns three outputs, `r` the correlation matrix, `n` the matrix of number of observation used in each pair of variables, and `p` the p-values.\n\nTo illustrate this concept, let's consider the `australia.soybean` data in object named `dat3`, and examine the relationship/association for all the possible pairs of the following variables `yield`, `height`, `lodging`, `size`, `protein`, and `oil`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Pearson correlation  \nlibrary(Hmisc)  \ndat3 |>  #the dataset  \n  as_tibble() |>   \n  select(-1) |> #deselect the non-numeric variable in the first column   \n  as.matrix() |> #convert the dataframe to matrix\n  rcorr(type = \"pearson\") #perform the correlation using the pearson correlation method dat3 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        yield height lodging  size protein   oil\nyield    1.00  -0.45   -0.61  0.66   -0.62  0.76\nheight  -0.45   1.00    0.88 -0.86    0.53 -0.80\nlodging -0.61   0.88    1.00 -0.87    0.65 -0.87\nsize     0.66  -0.86   -0.87  1.00   -0.55  0.91\nprotein -0.62   0.53    0.65 -0.55    1.00 -0.78\noil      0.76  -0.80   -0.87  0.91   -0.78  1.00\n\nn= 58 \n\n\nP\n        yield height lodging size  protein oil  \nyield         4e-04  0e+00   0e+00 0e+00   0e+00\nheight  4e-04        0e+00   0e+00 0e+00   0e+00\nlodging 0e+00 0e+00          0e+00 0e+00   0e+00\nsize    0e+00 0e+00  0e+00         0e+00   0e+00\nprotein 0e+00 0e+00  0e+00   0e+00         0e+00\noil     0e+00 0e+00  0e+00   0e+00 0e+00        \n```\n\n\n:::\n:::\n\n\n\nLet us assume the quantitative variables are not normally distributed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Spearman correlation  \nlibrary(Hmisc)  \ndat3 |> #the dataset   \n  select(-1) |> #deselect the non-numeric variable in the first column   \n  as.matrix() |> #convert the dataframe to matrix\n  rcorr(type = \"spearman\") #perform the correlation using the spearman rank correlation method\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        yield height lodging  size protein   oil\nyield    1.00  -0.44   -0.65  0.71   -0.64  0.74\nheight  -0.44   1.00    0.84 -0.74    0.63 -0.74\nlodging -0.65   0.84    1.00 -0.86    0.69 -0.86\nsize     0.71  -0.74   -0.86  1.00   -0.68  0.94\nprotein -0.64   0.63    0.69 -0.68    1.00 -0.80\noil      0.74  -0.74   -0.86  0.94   -0.80  1.00\n\nn= 58 \n\n\nP\n        yield height lodging size  protein oil  \nyield         5e-04  0e+00   0e+00 0e+00   0e+00\nheight  5e-04        0e+00   0e+00 0e+00   0e+00\nlodging 0e+00 0e+00          0e+00 0e+00   0e+00\nsize    0e+00 0e+00  0e+00         0e+00   0e+00\nprotein 0e+00 0e+00  0e+00   0e+00         0e+00\noil     0e+00 0e+00  0e+00   0e+00 0e+00        \n```\n\n\n:::\n:::\n\n\n\nThis shows the correlation matrix with yield, height, lodging, size, protein and oil as the variables. The numbers in the matrix reveal the following correlations:\n\n-   yield and height: -0.44 (Moderate negative correlation)\n-   yield and lodging: -0.65 (strong negative correlation)\n-   yield and size: 0.71 (strong positive correlation)\n-   yield and protein: -0.64 (strong negative correlation)\n-   yield and oil: 0.74 (strong positive correlation)\n-   height and lodging: 0.84 (strong positive correlation)\n-   size and oil: 0.94 (very strong positive correlation)\n\nSince all p-values reported are very low, this suggests that all correlations calculated in the matrix are statistically significant.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}